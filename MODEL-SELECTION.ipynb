{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46fbcf3",
   "metadata": {},
   "source": [
    "# Model Selection \n",
    "Simplied Version - last version 0425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a9124c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter '1. single' for single dataset or '2. multi' for multiple dataset: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import sys\n",
    "sys.path.append('./cs16')\n",
    "import cs16.prep as prep16\n",
    "import cs16.plot as plot16\n",
    "import cs16.build as build16\n",
    "imagesize = 64\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cs16.prep as prep16\n",
    "import cs16.plot as plot16\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "max_words=10000\n",
    "max_len=100\n",
    "imagesize =64\n",
    "\n",
    "\n",
    "#data_type = input(\"Enter '1. single' for single dataset or '2. multi' for multiple dataset: \")\n",
    "data_type = '1'\n",
    "if data_type == '1':\n",
    "    file_path = 'single.txt'\n",
    "    folder_path = './data/MVSA/single/'\n",
    "elif data_type == '2':\n",
    "    file_path = 'multi.txt'\n",
    "    folder_path = './data/MVSA/multiple/'\n",
    "else:\n",
    "    print(\"Invalid input. Please enter either 'single' or 'multi'.\")\n",
    "    exit()\n",
    "\n",
    "df = pd.read_csv(file_path, index_col=None, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "504af778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ausco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ausco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download stopwords and punkt tokenizer if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define a function to preprocess text\n",
    "def nlp_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs using regex\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove punctuation using regex\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenize text into individual words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Stem words using Porter Stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join words back into a single string\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the preprocess_text function to the 'tweet' column of the dataframe\n",
    "df['tweet'] = df['tweet'].apply(nlp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb90eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import time\n",
    "# stopwatch\n",
    "def some_function():\n",
    "    result = 0\n",
    "    for i in range(1000000):\n",
    "        result += i\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab47968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'single.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_text, y_text = prep16.preprocess_text(df)\n",
    "X_train_text, X_val_text, X_test_text, \\\n",
    "y_train_text, y_val_text, y_test_text = prep16.split_data(X_text, y_text, random_state=42)\n",
    "\n",
    "X_polar, y_polar = prep16.preprocess_text(df,label = 'polarity')\n",
    "X_train_polar, X_val_polar, X_test_polar, \\\n",
    "y_train_polar, y_val_polar, y_test_polar = prep16.split_data(X_polar, y_polar, random_state=42)\n",
    "\n",
    "image_data_s, image_label_s = prep16.preprocess_images(df, folder_path, imagesize)\n",
    "y_s = to_categorical(image_label_s, num_classes=3)\n",
    "\n",
    "X_train_image, X_val_image, X_test_image, \\\n",
    "y_train_image, y_val_image, y_test_image= prep16.split_data(image_data_s, y_s, random_state=42)\n",
    "\n",
    "y_train = to_categorical(y_train_polar, num_classes=3)\n",
    "y_val =to_categorical(y_val_polar, num_classes=3)\n",
    "y_test =to_categorical(y_test_polar, num_classes=3)\n",
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88971433",
   "metadata": {},
   "source": [
    "# Model　Selection\n",
    "\n",
    "- 單純合併 （last tested: 2025/05/09）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ecec1c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Fusion Feature shape (train): (3895, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ausco\\anaconda3\\lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.48459958932238195\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.2623    0.1778    0.2119        90\n",
      "     neutral     0.5857    0.7068    0.6405       266\n",
      "    positive     0.3048    0.2443    0.2712       131\n",
      "\n",
      "    accuracy                         0.4846       487\n",
      "   macro avg     0.3842    0.3763    0.3746       487\n",
      "weighted avg     0.4503    0.4846    0.4620       487\n",
      "\n",
      "Test Accuracy: 0.5297741273100616\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.2182    0.1558    0.1818        77\n",
      "     neutral     0.6164    0.7050    0.6577       278\n",
      "    positive     0.4386    0.3788    0.4065       132\n",
      "\n",
      "    accuracy                         0.5298       487\n",
      "   macro avg     0.4244    0.4132    0.4153       487\n",
      "weighted avg     0.5052    0.5298    0.5144       487\n",
      "\n",
      "Function: 499999500000\n",
      "Time Executed ===============>：53.7666 Sec\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#------------------------------------------------------------\n",
    "# after split\n",
    "# X_train_text, X_val_text, X_test_text,   y_train_text, y_val_text, y_test_text\n",
    "# X_train_image, X_val_image, X_test_image, y_train_image, y_val_image, y_test_image\n",
    "# Start to count time：\n",
    "#------------------------------------------------------------\n",
    "import time\n",
    "start_time = time.time()\n",
    "#------------------------------------------------------------\n",
    "########################################\n",
    "# 1. one-hot \n",
    "########################################\n",
    "y_train_int = np.argmax(y_train, axis=1)\n",
    "y_val_int   = np.argmax(y_val,   axis=1)\n",
    "y_test_int  = np.argmax(y_test,  axis=1)\n",
    "\n",
    "########################################\n",
    "# 2. Text Modality：Original RandomForest-> ExtraTree，Prob Vector(3-dim)\n",
    "########################################\n",
    "rf_text = LGBMClassifier(\n",
    "    n_estimators=80,\n",
    "    max_depth=4,\n",
    "    num_leaves=8,\n",
    "    learning_rate=0.1,\n",
    "    boosting_type='gbdt',\n",
    "    random_state=42\n",
    ")\n",
    "#\n",
    "rf_text.fit(X_train_text, y_train_int)\n",
    "\n",
    "# Each sample will get [p_neg, p_neu, p_pos]\n",
    "train_probs_text = rf_text.predict_proba(X_train_text)  # shape -> (n_train, 3)\n",
    "val_probs_text   = rf_text.predict_proba(X_val_text)    # shape -> (n_val,   3)\n",
    "test_probs_text  = rf_text.predict_proba(X_test_text)   # shape -> (n_test,  3)\n",
    "\n",
    "########################################\n",
    "# 3. Image Modality：\n",
    "########################################\n",
    "X_train_img_flat = X_train_image.reshape(X_train_image.shape[0], -1)\n",
    "X_val_img_flat   = X_val_image.reshape(X_val_image.shape[0],   -1)\n",
    "X_test_img_flat  = X_test_image.reshape(X_test_image.shape[0], -1)\n",
    "\n",
    "rf_image = LGBMClassifier(\n",
    "    n_estimators=80,\n",
    "    max_depth=4,\n",
    "    num_leaves=8,\n",
    "    learning_rate=0.1,\n",
    "    boosting_type='gbdt',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_image.fit(X_train_img_flat, y_train_int)\n",
    "\n",
    "train_probs_image = rf_image.predict_proba(X_train_img_flat)  # (n_train, 3)\n",
    "val_probs_image   = rf_image.predict_proba(X_val_img_flat)    # (n_val,   3)\n",
    "test_probs_image  = rf_image.predict_proba(X_test_img_flat)   # (n_test,  3)\n",
    "\n",
    "########################################\n",
    "# 4. Global Fusion：Concatenate Text(3) + Image(3) -> 6 dims\n",
    "########################################\n",
    "X_train_global = np.concatenate([train_probs_text, train_probs_image], axis=1)  # (n_train, 6)\n",
    "X_val_global   = np.concatenate([val_probs_text,   val_probs_image],   axis=1)  # (n_val,   6)\n",
    "X_test_global  = np.concatenate([test_probs_text,  test_probs_image],  axis=1)  # (n_test,  6)\n",
    "\n",
    "print(\"Global Fusion Feature shape (train):\", X_train_global.shape)\n",
    "\n",
    "########################################\n",
    "# 5. Final Classifier\n",
    "########################################\n",
    "global_clf =  xgb.XGBClassifier(350, max_depth=5, random_state=42)#LogisticRegression(max_iter=500, random_state=42)\n",
    "global_clf.fit(X_train_global, y_train_int)\n",
    "\n",
    "# Validation\n",
    "val_pred = global_clf.predict(X_val_global)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_int, val_pred))\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val_int, val_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "\n",
    "# Test\n",
    "test_pred = global_clf.predict(X_test_global)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_int, test_pred))\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test_int, test_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "\n",
    "#------------------------------------------------------------\n",
    "\n",
    "output = some_function()\n",
    "print(f\"Function: {output}\")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# TIME TAKEN\n",
    "print(f\"Time Executed ===============>：{elapsed_time:.4f} Sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d43b67",
   "metadata": {},
   "source": [
    "# Extra Tree Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "80c14683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ausco\\anaconda3\\lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5092402464065708\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.2500    0.0778    0.1186        90\n",
      "     neutral     0.6000    0.7331    0.6599       266\n",
      "    positive     0.3433    0.3511    0.3472       131\n",
      "\n",
      "    accuracy                         0.5092       487\n",
      "   macro avg     0.3978    0.3873    0.3752       487\n",
      "weighted avg     0.4663    0.5092    0.4757       487\n",
      "\n",
      "Test Accuracy: 0.5297741273100616\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.4375    0.0909    0.1505        77\n",
      "     neutral     0.6164    0.7050    0.6577       278\n",
      "    positive     0.3595    0.4167    0.3860       132\n",
      "\n",
      "    accuracy                         0.5298       487\n",
      "   macro avg     0.4711    0.4042    0.3981       487\n",
      "weighted avg     0.5184    0.5298    0.5039       487\n",
      "\n",
      "Time Executed =====ExtraTree==========>：6.5392 Sec\n"
     ]
    }
   ],
   "source": [
    "global_clf =  xgb.XGBClassifier(350, max_depth=5, random_state=42)#LogisticRegression(max_iter=500, random_state=42)\n",
    "global_clf.fit(X_train_global, y_train_int)\n",
    "\n",
    "# Validation\n",
    "val_pred = global_clf.predict(X_val_global)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_int, val_pred))\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val_int, val_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "\n",
    "# Test\n",
    "test_pred = global_clf.predict(X_test_global)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_int, test_pred))\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test_int, test_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "# TIME TAKEN\n",
    "print(f\"Time Executed =====ExtraTree==========>：{elapsed_time:.4f} Sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac408e",
   "metadata": {},
   "source": [
    "# LGBM COPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "861f664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ausco\\anaconda3\\lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5728952772073922\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.5000    0.0556    0.1000        90\n",
      "     neutral     0.5837    0.9436    0.7213       266\n",
      "    positive     0.4894    0.1756    0.2584       131\n",
      "\n",
      "    accuracy                         0.5729       487\n",
      "   macro avg     0.5244    0.3916    0.3599       487\n",
      "weighted avg     0.5429    0.5729    0.4820       487\n",
      "\n",
      "Test Accuracy: 0.5811088295687885\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.6000    0.0390    0.0732        77\n",
      "     neutral     0.5990    0.9029    0.7202       278\n",
      "    positive     0.4603    0.2197    0.2974       132\n",
      "\n",
      "    accuracy                         0.5811       487\n",
      "   macro avg     0.5531    0.3872    0.3636       487\n",
      "weighted avg     0.5616    0.5811    0.5033       487\n",
      "\n",
      "Time Executed =====LGBM==========>：189.1635 Sec\n"
     ]
    }
   ],
   "source": [
    "global_clf =  xgb.XGBClassifier(350, max_depth=5, random_state=42)#LogisticRegression(max_iter=500, random_state=42)\n",
    "global_clf.fit(X_train_global, y_train_int)\n",
    "\n",
    "# Validation\n",
    "val_pred = global_clf.predict(X_val_global)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_int, val_pred))\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val_int, val_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "\n",
    "# Test\n",
    "test_pred = global_clf.predict(X_test_global)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_int, test_pred))\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test_int, test_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "# TIME TAKEN\n",
    "print(f\"Time Executed =====LGBM==========>：{elapsed_time:.4f} Sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601292c",
   "metadata": {},
   "source": [
    "# ML Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2da83864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ausco\\anaconda3\\lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Fusion Feature shape (train): (3895, 6)\n",
      "Validation Accuracy: 0.5338809034907598\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.3750    0.0667    0.1132        90\n",
      "     neutral     0.5732    0.8835    0.6953       266\n",
      "    positive     0.3115    0.1450    0.1979       131\n",
      "\n",
      "    accuracy                         0.5339       487\n",
      "   macro avg     0.4199    0.3651    0.3355       487\n",
      "weighted avg     0.4662    0.5339    0.4539       487\n",
      "\n",
      "Test Accuracy: 0.5749486652977412\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.3750    0.0390    0.0706        77\n",
      "     neutral     0.5980    0.8669    0.7078       278\n",
      "    positive     0.4737    0.2727    0.3462       132\n",
      "\n",
      "    accuracy                         0.5749       487\n",
      "   macro avg     0.4822    0.3929    0.3748       487\n",
      "weighted avg     0.5291    0.5749    0.5090       487\n",
      "\n",
      "Function: 499999500000\n",
      "Time Executed ===============>：368.0843 Sec\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "#------------------------------------------------------------\n",
    "# after split\n",
    "# X_train_text, X_val_text, X_test_text,   y_train_text, y_val_text, y_test_text\n",
    "# X_train_image, X_val_image, X_test_image, y_train_image, y_val_image, y_test_image\n",
    "# Start to count time：\n",
    "#------------------------------------------------------------\n",
    "import time\n",
    "start_time = time.time()\n",
    "#------------------------------------------------------------\n",
    "########################################\n",
    "# 1. one-hot \n",
    "########################################\n",
    "y_train_int = np.argmax(y_train, axis=1)\n",
    "y_val_int   = np.argmax(y_val,   axis=1)\n",
    "y_test_int  = np.argmax(y_test,  axis=1)\n",
    "\n",
    "########################################\n",
    "# 2. Text Modality：Original RandomForest-> ExtraTree，Prob Vector(3-dim)\n",
    "########################################\n",
    "rf_text = xgb.XGBClassifier(100, max_depth=5, random_state=42)\n",
    "#RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_text.fit(X_train_text, y_train_int)\n",
    "\n",
    "# Each sample will get [p_neg, p_neu, p_pos]\n",
    "train_probs_text = rf_text.predict_proba(X_train_text)  # shape -> (n_train, 3)\n",
    "val_probs_text   = rf_text.predict_proba(X_val_text)    # shape -> (n_val,   3)\n",
    "test_probs_text  = rf_text.predict_proba(X_test_text)   # shape -> (n_test,  3)\n",
    "\n",
    "########################################\n",
    "# 3. Image Modality：\n",
    "########################################\n",
    "X_train_img_flat = X_train_image.reshape(X_train_image.shape[0], -1)\n",
    "X_val_img_flat   = X_val_image.reshape(X_val_image.shape[0],   -1)\n",
    "X_test_img_flat  = X_test_image.reshape(X_test_image.shape[0], -1)\n",
    "\n",
    "rf_image = xgb.XGBClassifier(100, max_depth=5, random_state=42)\n",
    "\n",
    "rf_image.fit(X_train_img_flat, y_train_int)\n",
    "\n",
    "train_probs_image = rf_image.predict_proba(X_train_img_flat)  # (n_train, 3)\n",
    "val_probs_image   = rf_image.predict_proba(X_val_img_flat)    # (n_val,   3)\n",
    "test_probs_image  = rf_image.predict_proba(X_test_img_flat)   # (n_test,  3)\n",
    "\n",
    "########################################\n",
    "# 4. Global Fusion：Concatenate Text(3) + Image(3) -> 6 dims\n",
    "########################################\n",
    "X_train_global = np.concatenate([train_probs_text, train_probs_image], axis=1)  # (n_train, 6)\n",
    "X_val_global   = np.concatenate([val_probs_text,   val_probs_image],   axis=1)  # (n_val,   6)\n",
    "X_test_global  = np.concatenate([test_probs_text,  test_probs_image],  axis=1)  # (n_test,  6)\n",
    "\n",
    "print(\"Global Fusion Feature shape (train):\", X_train_global.shape)\n",
    "\n",
    "########################################\n",
    "# 5. Final Classifier\n",
    "########################################\n",
    "global_clf =  xgb.XGBClassifier(350, max_depth=5, random_state=42)#LogisticRegression(max_iter=500, random_state=42)\n",
    "global_clf.fit(X_train_global, y_train_int)\n",
    "\n",
    "# Validation\n",
    "val_pred = global_clf.predict(X_val_global)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_int, val_pred))\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val_int, val_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "\n",
    "# Test\n",
    "test_pred = global_clf.predict(X_test_global)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_int, test_pred))\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test_int, test_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "\n",
    "#------------------------------------------------------------\n",
    "\n",
    "output = some_function()\n",
    "print(f\"Function: {output}\")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# TIME TAKEN\n",
    "print(f\"Time Executed ===============>：{elapsed_time:.4f} Sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3af06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76f188d9",
   "metadata": {},
   "source": [
    "# SVM Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9719906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ausco\\anaconda3\\lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3264887063655031\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.1719    0.3667    0.2340        90\n",
      "     neutral     0.6154    0.3008    0.4040       266\n",
      "    positive     0.2788    0.3511    0.3108       131\n",
      "\n",
      "    accuracy                         0.3265       487\n",
      "   macro avg     0.3553    0.3395    0.3163       487\n",
      "weighted avg     0.4429    0.3265    0.3475       487\n",
      "\n",
      "Test Accuracy: 0.3839835728952772\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.2081    0.4675    0.2880        77\n",
      "     neutral     0.6042    0.3129    0.4123       278\n",
      "    positive     0.3765    0.4848    0.4238       132\n",
      "\n",
      "    accuracy                         0.3840       487\n",
      "   macro avg     0.3962    0.4218    0.3747       487\n",
      "weighted avg     0.4798    0.3840    0.3958       487\n",
      "\n",
      "Time Executed ==SVM=============>：1065.0313 Sec\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# 5. Final Classifier\n",
    "########################################\n",
    "global_clf =  xgb.XGBClassifier(350, max_depth=5, random_state=42)#LogisticRegression(max_iter=500, random_state=42)\n",
    "global_clf.fit(X_train_global, y_train_int)\n",
    "\n",
    "# Validation\n",
    "val_pred = global_clf.predict(X_val_global)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_int, val_pred))\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val_int, val_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "\n",
    "# Test\n",
    "test_pred = global_clf.predict(X_test_global)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_int, test_pred))\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test_int, test_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "print(f\"Time Executed ==SVM=============>：{elapsed_time:.4f} Sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1442a511",
   "metadata": {},
   "source": [
    "# Logit Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "26649638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ausco\\anaconda3\\lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.45790554414784396\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.2838    0.2333    0.2561        90\n",
      "     neutral     0.5911    0.5977    0.5944       266\n",
      "    positive     0.2986    0.3282    0.3127       131\n",
      "\n",
      "    accuracy                         0.4579       487\n",
      "   macro avg     0.3912    0.3864    0.3877       487\n",
      "weighted avg     0.4556    0.4579    0.4561       487\n",
      "\n",
      "Test Accuracy: 0.45790554414784396\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.1618    0.1429    0.1517        77\n",
      "     neutral     0.5788    0.6079    0.5930       278\n",
      "    positive     0.3386    0.3258    0.3320       132\n",
      "\n",
      "    accuracy                         0.4579       487\n",
      "   macro avg     0.3597    0.3588    0.3589       487\n",
      "weighted avg     0.4477    0.4579    0.4525       487\n",
      "\n",
      "Time Executed ==LOGIT=============>：6.8198 Sec\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# 5. Final Classifier\n",
    "########################################\n",
    "global_clf =  xgb.XGBClassifier(350, max_depth=5, random_state=42)#LogisticRegression(max_iter=500, random_state=42)\n",
    "global_clf.fit(X_train_global, y_train_int)\n",
    "\n",
    "# Validation\n",
    "val_pred = global_clf.predict(X_val_global)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_int, val_pred))\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val_int, val_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "\n",
    "# Test\n",
    "test_pred = global_clf.predict(X_test_global)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_int, test_pred))\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test_int, test_pred,\n",
    "                            digits=4,\n",
    "                            target_names=['negative','neutral','positive']))\n",
    "print(f\"Time Executed ==LOGIT=============>：{elapsed_time:.4f} Sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd78ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
